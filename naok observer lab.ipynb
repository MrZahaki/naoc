{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observer Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### system description\n",
    "\n",
    "$$\n",
    "\\dot{x}_1 = -\\sin^2{(2x_1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Hossein\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from naoc.observer import Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = tf.convert_to_tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = tf.reshape(a, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 2, 3, 4, 5])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(at, (-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5008017424121425\n",
      "0.49912550058775296\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['rbf_layer_23/Variable:0', 'rbf_layer_23/Variable:0', 'rbf_layer_23/Variable:0', 'dense_23/kernel:0', 'dense_23/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'rbf_layer_23/Variable:0' shape=(1, 10) dtype=float32, numpy=\narray([[ 0.7175464 ,  0.7384171 , -0.0395155 ,  0.17061496, -0.24055281,\n         0.3970582 , -0.62576514,  0.18615174,  0.65763944,  0.10982978]],\n      dtype=float32)>), (None, <tf.Variable 'rbf_layer_23/Variable:0' shape=(1, 10) dtype=float32, numpy=\narray([[-0.65289295,  0.22607154, -0.7189119 ,  0.45951015,  0.3938678 ,\n        -0.21648026, -0.49301788,  0.6375559 , -0.23412591,  0.40332872]],\n      dtype=float32)>), (None, <tf.Variable 'rbf_layer_23/Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_23/kernel:0' shape=(10, 1) dtype=float32, numpy=\narray([[-0.7271887 ],\n       [ 0.15590829],\n       [-0.3667188 ],\n       [ 0.14605552],\n       [-0.04471874],\n       [ 0.28232938],\n       [ 0.49594682],\n       [-0.14069378],\n       [ 0.46108967],\n       [ 0.5879975 ]], dtype=float32)>), (None, <tf.Variable 'dense_23/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m target \u001b[38;5;241m=\u001b[39m system_dynamics(t)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Execute the observer\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43mobserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m state_buffer\u001b[38;5;241m.\u001b[39mappend(states[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     39\u001b[0m output_buffer\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[1;32mc:\\Users\\Hossein\\Documents\\Master’s degree education\\applied nonlinear control\\project\\naoc\\naoc\\observer.py:54\u001b[0m, in \u001b[0;36mObserver.estimate\u001b[1;34m(self, state, controller, output, target, forgetting_rate)\u001b[0m\n\u001b[0;32m     52\u001b[0m output_error \u001b[38;5;241m=\u001b[39m target \u001b[38;5;241m-\u001b[39m output\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# print(state.reshape(-1, 1))\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforgetting_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforgetting_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_main_solver\u001b[38;5;241m.\u001b[39mupdate(state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], state, controller, output_error)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state\n",
      "File \u001b[1;32mc:\\Users\\Hossein\\Documents\\Master’s degree education\\applied nonlinear control\\project\\naoc\\naoc\\observer.py:47\u001b[0m, in \u001b[0;36mObserver.update_weights\u001b[1;34m(self, output, target, forgetting_rate)\u001b[0m\n\u001b[0;32m     45\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(loss)\n\u001b[0;32m     46\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrbfnn_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Hossein\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1222\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1218\u001b[0m experimental_aggregate_gradients \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperimental_aggregate_gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m )\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m-> 1222\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Hossein\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1184\u001b[0m, in \u001b[0;36mOptimizer.aggregate_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grads_and_vars\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_reduce_sum_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hossein\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\utils.py:33\u001b[0m, in \u001b[0;36mall_reduce_sum_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all-reduced gradients aggregated via summation.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m  List of (gradient, variable) pairs where gradients have been all-reduced.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(grads_and_vars)\n\u001b[1;32m---> 33\u001b[0m filtered_grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_empty_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filtered_grads_and_vars:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mstrategy_supports_no_merge_call():\n",
      "File \u001b[1;32mc:\\Users\\Hossein\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\utils.py:77\u001b[0m, in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filtered:\n\u001b[0;32m     76\u001b[0m     variable \u001b[38;5;241m=\u001b[39m ([v\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m _, v \u001b[38;5;129;01min\u001b[39;00m grads_and_vars],)\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo gradients provided for any variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided `grads_and_vars` is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrads_and_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m     )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vars_with_empty_grads:\n\u001b[0;32m     82\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients do not exist for variables \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m when minimizing the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss. If you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre using `model.compile()`, did you forget to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovide a `loss` argument?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     86\u001b[0m         ([v\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m vars_with_empty_grads]),\n\u001b[0;32m     87\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: (['rbf_layer_23/Variable:0', 'rbf_layer_23/Variable:0', 'rbf_layer_23/Variable:0', 'dense_23/kernel:0', 'dense_23/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'rbf_layer_23/Variable:0' shape=(1, 10) dtype=float32, numpy=\narray([[ 0.7175464 ,  0.7384171 , -0.0395155 ,  0.17061496, -0.24055281,\n         0.3970582 , -0.62576514,  0.18615174,  0.65763944,  0.10982978]],\n      dtype=float32)>), (None, <tf.Variable 'rbf_layer_23/Variable:0' shape=(1, 10) dtype=float32, numpy=\narray([[-0.65289295,  0.22607154, -0.7189119 ,  0.45951015,  0.3938678 ,\n        -0.21648026, -0.49301788,  0.6375559 , -0.23412591,  0.40332872]],\n      dtype=float32)>), (None, <tf.Variable 'rbf_layer_23/Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_23/kernel:0' shape=(10, 1) dtype=float32, numpy=\narray([[-0.7271887 ],\n       [ 0.15590829],\n       [-0.3667188 ],\n       [ 0.14605552],\n       [-0.04471874],\n       [ 0.28232938],\n       [ 0.49594682],\n       [-0.14069378],\n       [ 0.46108967],\n       [ 0.5879975 ]], dtype=float32)>), (None, <tf.Variable 'dense_23/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>))."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the system dynamics\n",
    "def system_dynamics(x):\n",
    "    return -np.sin(2 * x) ** 2\n",
    "\n",
    "\n",
    "# Set up the observer parameters\n",
    "observer_gain = 0.1\n",
    "rbf_units = 10\n",
    "learning_rate = 0.01\n",
    "solver_step = 0.001\n",
    " \n",
    "\n",
    "# Initialize the Observer\n",
    "observer = Observer(rbf_units=rbf_units, observer_gain=observer_gain, learning_rate=learning_rate)\n",
    "# Set initial conditions and simulation parameters\n",
    "initial_state = np.array([0.5])  # Initial state for x1\n",
    "simulation_time = 10\n",
    "time_step = 0.01\n",
    "time_points = np.arange(0, simulation_time, time_step)\n",
    "\n",
    "# Simulate the system using the Observer\n",
    "states = initial_state\n",
    "state_buffer = []\n",
    "output_buffer = []\n",
    "target_buffer = []\n",
    "\n",
    "for t in time_points[1:]:\n",
    "    # Compute the derivative\n",
    "    output = system_dynamics(states[0])\n",
    "    target = system_dynamics(t)\n",
    "    # Execute the observer\n",
    "    states = observer.estimate(\n",
    "        state=states, \n",
    "        controller=0.01, \n",
    "        output=output,\n",
    "        target=target)\n",
    "    \n",
    "    state_buffer.append(states[0])\n",
    "    output_buffer.append(output)\n",
    "    target_buffer.append(target)\n",
    "    \n",
    "\n",
    "# print(output_buffer)\n",
    "# Plot the output\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(time_points[:-1], output_buffer, label='esout (y_hat)')\n",
    "plt.plot(time_points[:-1], target_buffer, label='target (y)')\n",
    "plt.title('System Simulation using State Observer')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('State (x1)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
